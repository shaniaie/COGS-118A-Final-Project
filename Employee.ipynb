{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "      <th>left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "...                   ...              ...             ...   \n",
       "14994                0.40             0.57               2   \n",
       "14995                0.37             0.48               2   \n",
       "14996                0.37             0.53               2   \n",
       "14997                0.11             0.96               6   \n",
       "14998                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  \\\n",
       "0                       157                   3              0   \n",
       "1                       262                   6              0   \n",
       "2                       272                   4              0   \n",
       "3                       223                   5              0   \n",
       "4                       159                   3              0   \n",
       "...                     ...                 ...            ...   \n",
       "14994                   151                   3              0   \n",
       "14995                   160                   3              0   \n",
       "14996                   143                   3              0   \n",
       "14997                   280                   4              0   \n",
       "14998                   158                   3              0   \n",
       "\n",
       "       promotion_last_5years department  salary  left  \n",
       "0                          0      sales     low     1  \n",
       "1                          0      sales  medium     1  \n",
       "2                          0      sales  medium     1  \n",
       "3                          0      sales     low     1  \n",
       "4                          0      sales     low     1  \n",
       "...                      ...        ...     ...   ...  \n",
       "14994                      0    support     low     1  \n",
       "14995                      0    support     low     1  \n",
       "14996                      0    support     low     1  \n",
       "14997                      0    support     low     1  \n",
       "14998                      0    support     low     1  \n",
       "\n",
       "[14999 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('employee.csv')\n",
    "X = df.drop(['left'], axis=1)\n",
    "y = df['left']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCENT POSITIVE\n",
    "\n",
    "Finding percentage of positive label in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.80825388359224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_pos = ((df['left']== 1).sum() / len(df['left'])) * 100\n",
    "percent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.462863</td>\n",
       "      <td>-0.882040</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971113</td>\n",
       "      <td>1.220423</td>\n",
       "      <td>1.713436</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.593763</td>\n",
       "      <td>1.420657</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.971113</td>\n",
       "      <td>0.439508</td>\n",
       "      <td>1.028546</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.462863</td>\n",
       "      <td>-0.841993</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>-1.462863</td>\n",
       "      <td>-1.002181</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>-1.462863</td>\n",
       "      <td>-0.821970</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>-1.462863</td>\n",
       "      <td>-1.162368</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>1.782438</td>\n",
       "      <td>1.580845</td>\n",
       "      <td>0.343655</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>-1.462863</td>\n",
       "      <td>-0.862016</td>\n",
       "      <td>-0.341235</td>\n",
       "      <td>-0.411165</td>\n",
       "      <td>-0.147412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4    5    6    7    8   \\\n",
       "0     -1.462863 -0.882040 -0.341235 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "1      0.971113  1.220423  1.713436 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "2      2.593763  1.420657  0.343655 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "3      0.971113  0.439508  1.028546 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "4     -1.462863 -0.841993 -0.341235 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...       ...       ...  ...  ...  ...  ...   \n",
       "14994 -1.462863 -1.002181 -0.341235 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "14995 -1.462863 -0.821970 -0.341235 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "14996 -1.462863 -1.162368 -0.341235 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "14997  1.782438  1.580845  0.343655 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "14998 -1.462863 -0.862016 -0.341235 -0.411165 -0.147412  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        9    10   11   12   13   14   15   16   17  \n",
       "0      0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3      0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4      0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "14994  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "14995  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "14996  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "14997  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "14998  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[14999 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform X values into One Hot Encoding for categorical variables and Standardizing for numerical variables\n",
    "# https://stackoverflow.com/questions/43798377/one-hot-encode-categorical-variables-and-scale-continuous-ones-simultaneouely\n",
    "\n",
    "# Get categorical columns\n",
    "cat = list(X.select_dtypes(['object']).columns)\n",
    "# Get numerical columns\n",
    "cont = list(X.select_dtypes(['int64']).columns)\n",
    "\n",
    "# Scale numerical values\n",
    "cont_transform = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# Encode categorical values\n",
    "cat_transform = Pipeline(steps=[('categories', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "# Transform the dataset into the scaled and encoded version\n",
    "preprocessor = ColumnTransformer(transformers=[('cont', cont_transform, cont),\n",
    "                                               ('cat', cat_transform, cat)])\n",
    "X = pd.DataFrame(preprocessor.fit_transform(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_log = pd.DataFrame(columns=['LG: Accuracy','LG: Precision','LG: AUC','LG: F1'])\n",
    "    test_metrics_log = pd.DataFrame(columns=['LG: Accuracy','LG: Precision','LG: AUC','LG: F1'])\n",
    "    \n",
    "    pipe = Pipeline(steps=[('classifier', LogisticRegression())])\n",
    "\n",
    "    # Setting Parameters to L1 and L2 regularized + unregularized model\n",
    "    parameters = [{'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['saga'],\n",
    "                   'classifier__penalty': ['l1'],\n",
    "                   'classifier__C': np.logspace(-8,4,13)},\n",
    "                  {'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['sag', 'saga'],\n",
    "                   'classifier__penalty': ['none']},\n",
    "                  {'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['sag', 'saga'],\n",
    "                   'classifier__penalty': ['l2'],\n",
    "                   'classifier__C': np.logspace(-8,4,13)}]\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(pipe, parameters, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "\n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_log = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY MODEL\n",
    "    solution_log['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_accuracy:\n",
    "        accuracy_model = LogisticRegression(penalty = best_accuracy['classifier__penalty'],\n",
    "                                            C = best_accuracy['classifier__C'],\n",
    "                                            solver = best_accuracy['classifier__solver'],\n",
    "                                            max_iter = 5000,\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    else:\n",
    "        accuracy_model = LogisticRegression(penalty = best_accuracy['classifier__penalty'],\n",
    "                                            solver = best_accuracy['classifier__solver'],\n",
    "                                            max_iter = 5000,\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION MODEL\n",
    "    solution_log['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_precision:\n",
    "        precision_model = LogisticRegression(penalty = best_precision['classifier__penalty'],\n",
    "                                             C = best_precision['classifier__C'],\n",
    "                                             solver = best_precision['classifier__solver'],\n",
    "                                             max_iter = 5000,\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    else:\n",
    "        precision_model = LogisticRegression(penalty = best_precision['classifier__penalty'],\n",
    "                                             solver = best_precision['classifier__solver'],\n",
    "                                             max_iter = 5000,\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC MODEL\n",
    "    solution_log['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_roc_auc:\n",
    "        roc_model = LogisticRegression(penalty = best_roc_auc['classifier__penalty'],\n",
    "                                       C = best_roc_auc['classifier__C'],\n",
    "                                       solver = best_roc_auc['classifier__solver'],\n",
    "                                       max_iter = 5000,\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    else:\n",
    "        roc_model = LogisticRegression(penalty = best_roc_auc['classifier__penalty'],\n",
    "                                       solver = best_roc_auc['classifier__solver'],\n",
    "                                       max_iter = 5000,\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1 MODEL\n",
    "    solution_log['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_f1:\n",
    "        f1_model = LogisticRegression(penalty = best_f1['classifier__penalty'],\n",
    "                                      C = best_f1['classifier__C'],\n",
    "                                      solver = best_f1['classifier__solver'],\n",
    "                                      max_iter = 5000,\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    else:\n",
    "        f1_model = LogisticRegression(penalty = best_f1['classifier__penalty'],\n",
    "                                      solver = best_f1['classifier__solver'],\n",
    "                                      max_iter = 5000,\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    \n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_log = train_metrics_log.append({'LG: Accuracy': acc_train_score, 'LG: Precision': prec_train_score, \n",
    "                                          'LG: AUC': roc_train_score, 'LG: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_log = test_metrics_log.append({'LG: Accuracy': acc_test_score, 'LG: Precision': prec_test_score, \n",
    "                                          'LG: AUC': roc_test_score, 'LG: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_log, test_metrics_log, solution_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def randomForest(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_rf = pd.DataFrame(columns=['RF: Accuracy','RF: Precision','RF: AUC','RF: F1'])\n",
    "    test_metrics_rf = pd.DataFrame(columns=['RF: Accuracy','RF: Precision','RF: AUC','RF: F1'])\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "\n",
    "    # Setting parameters according to CNM06\n",
    "    param_grid = {\n",
    "        'n_estimators': [1024],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features': [1,2,4,6,8,12,16],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': ['balanced']}\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(estimator=randomForest, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "\n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_rf = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY MODEL\n",
    "    solution_rf['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    accuracy_model = RandomForestClassifier(n_estimators = best_accuracy['n_estimators'],\n",
    "                                            criterion = best_accuracy['criterion'],\n",
    "                                            max_features = best_accuracy['max_features'],\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION MODEL\n",
    "    solution_rf['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    precision_model = RandomForestClassifier(n_estimators = best_precision['n_estimators'],\n",
    "                                             criterion = best_precision['criterion'],\n",
    "                                             max_features = best_precision['max_features'],\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC MODEL\n",
    "    solution_rf['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    roc_model = RandomForestClassifier(n_estimators = best_roc_auc['n_estimators'],\n",
    "                                       criterion = best_roc_auc['criterion'],\n",
    "                                       max_features = best_roc_auc['max_features'],\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1 MODEL\n",
    "    solution_rf['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    f1_model = RandomForestClassifier(n_estimators = best_f1['n_estimators'],\n",
    "                                      criterion = best_f1['criterion'],\n",
    "                                      max_features = best_f1['max_features'],\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_rf = train_metrics_rf.append({'RF: Accuracy': acc_train_score, 'RF: Precision': prec_train_score,\n",
    "                                                'RF: AUC': roc_train_score, 'RF: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_rf = test_metrics_rf.append({'RF: Accuracy': acc_test_score, 'RF: Precision': prec_test_score,\n",
    "                                              'RF: AUC': roc_test_score, 'RF: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_rf, test_metrics_rf, solution_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTrees(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_dt = pd.DataFrame(columns=['DT: Accuracy','DT: Precision','DT: AUC','DT: F1'])\n",
    "    test_metrics_dt = pd.DataFrame(columns=['DT: Accuracy','DT: Precision','DT: AUC','DT: F1'])\n",
    "\n",
    "    pipe = Pipeline(steps=[('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "    # Setting parameters according to CNM06 + passing a list of min_samples_leaf\n",
    "    parameters = [{'classifier': [DecisionTreeClassifier(class_weight='balanced')],\n",
    "                   'classifier__criterion': ['gini', 'entropy'],\n",
    "                   'classifier__splitter': ['best'],\n",
    "                   'classifier__min_samples_leaf': [1,2,4,6,8,10,12,14,16,18]}]\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(estimator=pipe, param_grid=parameters, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "    \n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_dt = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY\n",
    "    solution_dt['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    accuracy_model = DecisionTreeClassifier(criterion = best_accuracy['classifier__criterion'],\n",
    "                                            splitter = best_accuracy['classifier__splitter'],\n",
    "                                            min_samples_leaf = best_accuracy['classifier__min_samples_leaf'],\n",
    "                                            class_weight = 'balanced')\n",
    "\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION\n",
    "    solution_dt['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    precision_model = DecisionTreeClassifier(criterion = best_precision['classifier__criterion'],\n",
    "                                             splitter = best_precision['classifier__splitter'],\n",
    "                                             min_samples_leaf = best_precision['classifier__min_samples_leaf'],\n",
    "                                             class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC\n",
    "    solution_dt['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    roc_model = DecisionTreeClassifier(criterion = best_roc_auc['classifier__criterion'],\n",
    "                                       splitter = best_roc_auc['classifier__splitter'],\n",
    "                                       min_samples_leaf = best_roc_auc['classifier__min_samples_leaf'],\n",
    "                                       class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1\n",
    "    solution_dt['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    f1_model = DecisionTreeClassifier(criterion = best_f1['classifier__criterion'],\n",
    "                                      splitter = best_f1['classifier__splitter'],\n",
    "                                      min_samples_leaf = best_f1['classifier__min_samples_leaf'],\n",
    "                                      class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_dt = train_metrics_dt.append({'DT: Accuracy': acc_train_score, 'DT: Precision': prec_train_score,\n",
    "                                                'DT: AUC': roc_train_score, 'DT: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_dt = test_metrics_dt.append({'DT: Accuracy': acc_test_score, 'DT: Precision': prec_test_score,\n",
    "                                              'DT: AUC': roc_test_score, 'DT: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_dt, test_metrics_dt, solution_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed:   58.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed:   59.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed:   47.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.5s finished\n"
     ]
    }
   ],
   "source": [
    "trials = 5\n",
    "train_metrics = pd.DataFrame()\n",
    "test_metrics = pd.DataFrame()\n",
    "solution_metrics = pd.DataFrame()\n",
    "\n",
    "# Running the trial five times\n",
    "for i in range(trials):\n",
    "    # Splitting data into train size = 5000\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, shuffle=True)\n",
    "    \n",
    "    train_log, test_log, solution_log = logisticRegression(X_train, X_test, y_train, y_test)\n",
    "    train_rf, test_rf, solution_rf = randomForest(X_train, X_test, y_train, y_test)\n",
    "    train_dt, test_dt, solution_dt = decisionTrees(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    train_metrics = train_metrics.append(pd.concat([train_log, train_rf, train_dt], axis=1))\n",
    "    test_metrics = test_metrics.append(pd.concat([test_log, test_rf, test_dt], axis=1))\n",
    "    solution_metrics = solution_metrics.append(pd.concat([solution_log, solution_rf, solution_dt], axis=1))\n",
    "\n",
    "# storing data into CSV file\n",
    "train_metrics.to_csv('employee_train.csv')\n",
    "test_metrics.to_csv('employee_test.csv')\n",
    "solution_metrics.to_csv('employee_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
