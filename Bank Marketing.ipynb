{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30488 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y      no      no   no   \n",
       "2       37     services  married          high.school      no     yes   no   \n",
       "3       40       admin.  married             basic.6y      no      no   no   \n",
       "4       56     services  married          high.school      no      no  yes   \n",
       "6       59       admin.  married  professional.course      no      no   no   \n",
       "...    ...          ...      ...                  ...     ...     ...  ...   \n",
       "41183   73      retired  married  professional.course      no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course      no      no   no   \n",
       "41185   56      retired  married    university.degree      no     yes   no   \n",
       "41186   44   technician  married  professional.course      no      no   no   \n",
       "41187   74      retired  married  professional.course      no     yes   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon  ...         1    999         0   \n",
       "2      telephone   may         mon  ...         1    999         0   \n",
       "3      telephone   may         mon  ...         1    999         0   \n",
       "4      telephone   may         mon  ...         1    999         0   \n",
       "6      telephone   may         mon  ...         1    999         0   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri  ...         1    999         0   \n",
       "41184   cellular   nov         fri  ...         1    999         0   \n",
       "41185   cellular   nov         fri  ...         2    999         0   \n",
       "41186   cellular   nov         fri  ...         1    999         0   \n",
       "41187   cellular   nov         fri  ...         3    999         1   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "6      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41187      failure         -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed  y  \n",
       "0           5191.0  0  \n",
       "2           5191.0  0  \n",
       "3           5191.0  0  \n",
       "4           5191.0  0  \n",
       "6           5191.0  0  \n",
       "...            ... ..  \n",
       "41183       4963.6  1  \n",
       "41184       4963.6  0  \n",
       "41185       4963.6  0  \n",
       "41186       4963.6  1  \n",
       "41187       4963.6  0  \n",
       "\n",
       "[30488 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', delimiter=';')\n",
    "df = df.replace(['unknown'], np.NaN)\n",
    "df = df.dropna()\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "X = df.drop(['y'], axis=1)\n",
    "y = df['y']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCENT POSITIVE\n",
    "\n",
    "Finding percentage of positive label in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.65743899239045"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_pos = ((df['y'] == 1).sum() / len(df['y'])) * 100\n",
    "percent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.642253</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.196452</td>\n",
       "      <td>-0.127944</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093870</td>\n",
       "      <td>-0.414520</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.642253</td>\n",
       "      <td>0.181559</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.932575</td>\n",
       "      <td>-0.460373</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30483</th>\n",
       "      <td>3.287410</td>\n",
       "      <td>0.284727</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30484</th>\n",
       "      <td>0.674513</td>\n",
       "      <td>0.471957</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>1.642253</td>\n",
       "      <td>-0.269321</td>\n",
       "      <td>-0.191702</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>0.480965</td>\n",
       "      <td>0.697398</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>-0.371616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>3.384184</td>\n",
       "      <td>-0.078270</td>\n",
       "      <td>0.175930</td>\n",
       "      <td>0.211887</td>\n",
       "      <td>1.541237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30488 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4    5    6    7    8   \\\n",
       "0      1.642253  0.005792 -0.559335  0.211887 -0.371616  0.0  0.0  0.0  1.0   \n",
       "1     -0.196452 -0.127944 -0.559335  0.211887 -0.371616  0.0  0.0  0.0  0.0   \n",
       "2      0.093870 -0.414520 -0.559335  0.211887 -0.371616  1.0  0.0  0.0  0.0   \n",
       "3      1.642253  0.181559 -0.559335  0.211887 -0.371616  0.0  0.0  0.0  0.0   \n",
       "4      1.932575 -0.460373 -0.559335  0.211887 -0.371616  1.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...       ...       ...  ...  ...  ...  ...   \n",
       "30483  3.287410  0.284727 -0.559335  0.211887 -0.371616  0.0  0.0  0.0  0.0   \n",
       "30484  0.674513  0.471957 -0.559335  0.211887 -0.371616  0.0  1.0  0.0  0.0   \n",
       "30485  1.642253 -0.269321 -0.191702  0.211887 -0.371616  0.0  0.0  0.0  0.0   \n",
       "30486  0.480965  0.697398 -0.559335  0.211887 -0.371616  0.0  0.0  0.0  0.0   \n",
       "30487  3.384184 -0.078270  0.175930  0.211887  1.541237  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        9   ...   42   43   44   45   46   47   48   49   50   51  \n",
       "0      0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1      0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2      0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3      0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4      0.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "30483  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "30484  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "30485  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "30486  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "30487  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[30488 rows x 52 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform X values into One Hot Encoding for categorical variables and Standardizing for numerical variables\n",
    "# https://stackoverflow.com/questions/43798377/one-hot-encode-categorical-variables-and-scale-continuous-ones-simultaneouely\n",
    "\n",
    "# Get categorical columns\n",
    "cat = list(X.select_dtypes(['object']).columns)\n",
    "# Get numerical columns\n",
    "cont = list(X.select_dtypes(['int64']).columns)\n",
    "\n",
    "# Scale numerical values\n",
    "cont_transform = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# Encode categorical values\n",
    "cat_transform = Pipeline(steps=[('categories', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "# Transform the dataset into the scaled and encoded version\n",
    "preprocessor = ColumnTransformer(transformers=[('cont', cont_transform, cont),\n",
    "                                               ('cat', cat_transform, cat)])\n",
    "X = pd.DataFrame(preprocessor.fit_transform(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_log = pd.DataFrame(columns=['LG: Accuracy','LG: Precision','LG: AUC','LG: F1'])\n",
    "    test_metrics_log = pd.DataFrame(columns=['LG: Accuracy','LG: Precision','LG: AUC','LG: F1'])\n",
    "    \n",
    "    pipe = Pipeline(steps=[('classifier', LogisticRegression())])\n",
    "\n",
    "    # Setting Parameters to L1 and L2 regularized + unregularized model\n",
    "    parameters = [{'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['saga'],\n",
    "                   'classifier__penalty': ['l1'],\n",
    "                   'classifier__C': np.logspace(-8,4,13)},\n",
    "                  {'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['sag', 'saga'],\n",
    "                   'classifier__penalty': ['none']},\n",
    "                  {'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['sag', 'saga'],\n",
    "                   'classifier__penalty': ['l2'],\n",
    "                   'classifier__C': np.logspace(-8,4,13)}]\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(pipe, parameters, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "\n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_log = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY MODEL\n",
    "    solution_log['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_accuracy:\n",
    "        accuracy_model = LogisticRegression(penalty = best_accuracy['classifier__penalty'],\n",
    "                                            C = best_accuracy['classifier__C'],\n",
    "                                            solver = best_accuracy['classifier__solver'],\n",
    "                                            max_iter = 5000,\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    else:\n",
    "        accuracy_model = LogisticRegression(penalty = best_accuracy['classifier__penalty'],\n",
    "                                            solver = best_accuracy['classifier__solver'],\n",
    "                                            max_iter = 5000,\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION MODEL\n",
    "    solution_log['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_precision:\n",
    "        precision_model = LogisticRegression(penalty = best_precision['classifier__penalty'],\n",
    "                                             C = best_precision['classifier__C'],\n",
    "                                             solver = best_precision['classifier__solver'],\n",
    "                                             max_iter = 5000,\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    else:\n",
    "        precision_model = LogisticRegression(penalty = best_precision['classifier__penalty'],\n",
    "                                             solver = best_precision['classifier__solver'],\n",
    "                                             max_iter = 5000,\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC MODEL\n",
    "    solution_log['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_roc_auc:\n",
    "        roc_model = LogisticRegression(penalty = best_roc_auc['classifier__penalty'],\n",
    "                                       C = best_roc_auc['classifier__C'],\n",
    "                                       solver = best_roc_auc['classifier__solver'],\n",
    "                                       max_iter = 5000,\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    else:\n",
    "        roc_model = LogisticRegression(penalty = best_roc_auc['classifier__penalty'],\n",
    "                                       solver = best_roc_auc['classifier__solver'],\n",
    "                                       max_iter = 5000,\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1 MODEL\n",
    "    solution_log['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_f1:\n",
    "        f1_model = LogisticRegression(penalty = best_f1['classifier__penalty'],\n",
    "                                      C = best_f1['classifier__C'],\n",
    "                                      solver = best_f1['classifier__solver'],\n",
    "                                      max_iter = 5000,\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    else:\n",
    "        f1_model = LogisticRegression(penalty = best_f1['classifier__penalty'],\n",
    "                                      solver = best_f1['classifier__solver'],\n",
    "                                      max_iter = 5000,\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    \n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_log = train_metrics_log.append({'LG: Accuracy': acc_train_score, 'LG: Precision': prec_train_score, \n",
    "                                          'LG: AUC': roc_train_score, 'LG: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_log = test_metrics_log.append({'LG: Accuracy': acc_test_score, 'LG: Precision': prec_test_score, \n",
    "                                          'LG: AUC': roc_test_score, 'LG: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_log, test_metrics_log, solution_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def randomForest(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_rf = pd.DataFrame(columns=['RF: Accuracy','RF: Precision','RF: AUC','RF: F1'])\n",
    "    test_metrics_rf = pd.DataFrame(columns=['RF: Accuracy','RF: Precision','RF: AUC','RF: F1'])\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "\n",
    "    # Setting parameters according to CNM06\n",
    "    param_grid = {\n",
    "        'n_estimators': [1024],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features': [1,2,4,6,8,12,16],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': ['balanced']}\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(estimator=randomForest, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "\n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_rf = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY MODEL\n",
    "    solution_rf['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    accuracy_model = RandomForestClassifier(n_estimators = best_accuracy['n_estimators'],\n",
    "                                            criterion = best_accuracy['criterion'],\n",
    "                                            max_features = best_accuracy['max_features'],\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION MODEL\n",
    "    solution_rf['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    precision_model = RandomForestClassifier(n_estimators = best_precision['n_estimators'],\n",
    "                                             criterion = best_precision['criterion'],\n",
    "                                             max_features = best_precision['max_features'],\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC MODEL\n",
    "    solution_rf['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    roc_model = RandomForestClassifier(n_estimators = best_roc_auc['n_estimators'],\n",
    "                                       criterion = best_roc_auc['criterion'],\n",
    "                                       max_features = best_roc_auc['max_features'],\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1 MODEL\n",
    "    solution_rf['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    f1_model = RandomForestClassifier(n_estimators = best_f1['n_estimators'],\n",
    "                                      criterion = best_f1['criterion'],\n",
    "                                      max_features = best_f1['max_features'],\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_rf = train_metrics_rf.append({'RF: Accuracy': acc_train_score, 'RF: Precision': prec_train_score,\n",
    "                                                'RF: AUC': roc_train_score, 'RF: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_rf = test_metrics_rf.append({'RF: Accuracy': acc_test_score, 'RF: Precision': prec_test_score,\n",
    "                                              'RF: AUC': roc_test_score, 'RF: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_rf, test_metrics_rf, solution_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTrees(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_dt = pd.DataFrame(columns=['DT: Accuracy','DT: Precision','DT: AUC','DT: F1'])\n",
    "    test_metrics_dt = pd.DataFrame(columns=['DT: Accuracy','DT: Precision','DT: AUC','DT: F1'])\n",
    "\n",
    "    pipe = Pipeline(steps=[('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "    # Setting parameters according to CNM06 + passing a list of min_samples_leaf\n",
    "    parameters = [{'classifier': [DecisionTreeClassifier(class_weight='balanced')],\n",
    "                   'classifier__criterion': ['gini', 'entropy'],\n",
    "                   'classifier__splitter': ['best'],\n",
    "                   'classifier__min_samples_leaf': [1,2,4,6,8,10,12,14,16,18]}]\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(estimator=pipe, param_grid=parameters, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "    \n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_dt = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY\n",
    "    solution_dt['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    accuracy_model = DecisionTreeClassifier(criterion = best_accuracy['classifier__criterion'],\n",
    "                                            splitter = best_accuracy['classifier__splitter'],\n",
    "                                            min_samples_leaf = best_accuracy['classifier__min_samples_leaf'],\n",
    "                                            class_weight = 'balanced')\n",
    "\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION\n",
    "    solution_dt['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    precision_model = DecisionTreeClassifier(criterion = best_precision['classifier__criterion'],\n",
    "                                             splitter = best_precision['classifier__splitter'],\n",
    "                                             min_samples_leaf = best_precision['classifier__min_samples_leaf'],\n",
    "                                             class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC\n",
    "    solution_dt['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    roc_model = DecisionTreeClassifier(criterion = best_roc_auc['classifier__criterion'],\n",
    "                                       splitter = best_roc_auc['classifier__splitter'],\n",
    "                                       min_samples_leaf = best_roc_auc['classifier__min_samples_leaf'],\n",
    "                                       class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1\n",
    "    solution_dt['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    f1_model = DecisionTreeClassifier(criterion = best_f1['classifier__criterion'],\n",
    "                                      splitter = best_f1['classifier__splitter'],\n",
    "                                      min_samples_leaf = best_f1['classifier__min_samples_leaf'],\n",
    "                                      class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_dt = train_metrics_dt.append({'DT: Accuracy': acc_train_score, 'DT: Precision': prec_train_score,\n",
    "                                                'DT: AUC': roc_train_score, 'DT: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_dt = test_metrics_dt.append({'DT: Accuracy': acc_test_score, 'DT: Precision': prec_test_score,\n",
    "                                              'DT: AUC': roc_test_score, 'DT: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_dt, test_metrics_dt, solution_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING DATASET ON ALL THREE ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 49.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 19.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  9.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 12.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "trials = 5\n",
    "train_metrics = pd.DataFrame()\n",
    "test_metrics = pd.DataFrame()\n",
    "solution_metrics = pd.DataFrame()\n",
    "\n",
    "# Running the trial five times\n",
    "for i in range(trials):\n",
    "    # Splitting data into train size = 5000\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, shuffle=True)\n",
    "    \n",
    "    train_log, test_log, solution_log = logisticRegression(X_train, X_test, y_train, y_test)\n",
    "    train_rf, test_rf, solution_rf = randomForest(X_train, X_test, y_train, y_test)\n",
    "    train_dt, test_dt, solution_dt = decisionTrees(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    train_metrics = train_metrics.append(pd.concat([train_log, train_rf, train_dt], axis=1))\n",
    "    test_metrics = test_metrics.append(pd.concat([test_log, test_rf, test_dt], axis=1))\n",
    "    solution_metrics = solution_metrics.append(pd.concat([solution_log, solution_rf, solution_dt], axis=1))\n",
    "\n",
    "# storing data into CSV file\n",
    "train_metrics.to_csv('bank_train.csv')\n",
    "test_metrics.to_csv('bank_test.csv')\n",
    "solution_metrics.to_csv('bank_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
