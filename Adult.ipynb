{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Cleaning Data\n",
    "colnames = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
    "            'marital-status', 'occupation', 'relationship', 'race', 'sex', \n",
    "            'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv('adult.csv', names = colnames)\n",
    "df = df.replace([' ?', ' <=50K.', ' >50K.', ' <=50K', ' >50K'], [np.NaN, 0, 1, 0, 1])\n",
    "df = df.dropna()\n",
    "df = df.replace([])\n",
    "\n",
    "X = df.drop(['income'], axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCENT POSITIVE\n",
    "\n",
    "Finding percentage of positive label in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.78439697492371"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_pos = ((df['income']== 1).sum() / len(df['income'])) * 100\n",
    "percent_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034201</td>\n",
       "      <td>-1.062295</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>0.142888</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866417</td>\n",
       "      <td>-1.007438</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-2.326738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.041455</td>\n",
       "      <td>0.245284</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.093385</td>\n",
       "      <td>0.425853</td>\n",
       "      <td>-1.221559</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.798015</td>\n",
       "      <td>1.407393</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45217</th>\n",
       "      <td>-0.419735</td>\n",
       "      <td>0.525154</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45218</th>\n",
       "      <td>0.034201</td>\n",
       "      <td>0.243135</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.411249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45219</th>\n",
       "      <td>-0.041455</td>\n",
       "      <td>1.753613</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45220</th>\n",
       "      <td>0.412481</td>\n",
       "      <td>-1.001947</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>0.579985</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45221</th>\n",
       "      <td>-0.268423</td>\n",
       "      <td>-0.071818</td>\n",
       "      <td>1.128753</td>\n",
       "      <td>-0.146733</td>\n",
       "      <td>-0.21878</td>\n",
       "      <td>1.587523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3        4         5    6    7    \\\n",
       "0      0.034201 -1.062295  1.128753  0.142888 -0.21878 -0.078120  0.0  0.0   \n",
       "1      0.866417 -1.007438  1.128753 -0.146733 -0.21878 -2.326738  0.0  0.0   \n",
       "2     -0.041455  0.245284 -0.438122 -0.146733 -0.21878 -0.078120  0.0  0.0   \n",
       "3      1.093385  0.425853 -1.221559 -0.146733 -0.21878 -0.078120  0.0  0.0   \n",
       "4     -0.798015  1.407393  1.128753 -0.146733 -0.21878 -0.078120  0.0  0.0   \n",
       "...         ...       ...       ...       ...      ...       ...  ...  ...   \n",
       "45217 -0.419735  0.525154  1.128753 -0.146733 -0.21878 -0.078120  0.0  0.0   \n",
       "45218  0.034201  0.243135  1.128753 -0.146733 -0.21878 -0.411249  0.0  0.0   \n",
       "45219 -0.041455  1.753613  1.128753 -0.146733 -0.21878  0.754701  0.0  0.0   \n",
       "45220  0.412481 -1.001947  1.128753  0.579985 -0.21878 -0.078120  0.0  0.0   \n",
       "45221 -0.268423 -0.071818  1.128753 -0.146733 -0.21878  1.587523  0.0  0.0   \n",
       "\n",
       "       8    9    ...  94   95   96   97   98   99   100  101  102  103  \n",
       "0      0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1      0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2      1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3      1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4      1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "45217  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "45218  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "45219  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "45220  1.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "45221  0.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[45222 rows x 104 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform X values into One Hot Encoding for categorical variables and Standardizing for numerical variables\n",
    "# https://stackoverflow.com/questions/43798377/one-hot-encode-categorical-variables-and-scale-continuous-ones-simultaneouely\n",
    "\n",
    "# Get categorical columns\n",
    "cat = list(X.select_dtypes(['object']).columns)\n",
    "# Get numerical columns\n",
    "cont = list(X.select_dtypes(['int64']).columns)\n",
    "\n",
    "# Scale numerical values\n",
    "cont_transform = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# Encode categorical values\n",
    "cat_transform = Pipeline(steps=[('categories', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "# Transform the dataset into the scaled and encoded version\n",
    "preprocessor = ColumnTransformer(transformers=[('cont', cont_transform, cont),\n",
    "                                               ('cat', cat_transform, cat)])\n",
    "X = pd.DataFrame(preprocessor.fit_transform(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_log = pd.DataFrame(columns=['LG: Accuracy','LG: Precision','LG: AUC','LG: F1'])\n",
    "    test_metrics_log = pd.DataFrame(columns=['LG: Accuracy','LG: Precision','LG: AUC','LG: F1'])\n",
    "    \n",
    "    pipe = Pipeline(steps=[('classifier', LogisticRegression())])\n",
    "\n",
    "    # Setting Parameters to L1 and L2 regularized + unregularized model\n",
    "    parameters = [{'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['saga'],\n",
    "                   'classifier__penalty': ['l1'],\n",
    "                   'classifier__C': np.logspace(-8,4,13)},\n",
    "                  {'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['sag', 'saga'],\n",
    "                   'classifier__penalty': ['none']},\n",
    "                  {'classifier': [LogisticRegression(max_iter=5000, n_jobs=-1, class_weight='balanced')],\n",
    "                   'classifier__solver': ['sag', 'saga'],\n",
    "                   'classifier__penalty': ['l2'],\n",
    "                   'classifier__C': np.logspace(-8,4,13)}]\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(pipe, parameters, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "\n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_log = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY MODEL\n",
    "    solution_log['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_accuracy:\n",
    "        accuracy_model = LogisticRegression(penalty = best_accuracy['classifier__penalty'],\n",
    "                                            C = best_accuracy['classifier__C'],\n",
    "                                            solver = best_accuracy['classifier__solver'],\n",
    "                                            max_iter = 5000,\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    else:\n",
    "        accuracy_model = LogisticRegression(penalty = best_accuracy['classifier__penalty'],\n",
    "                                            solver = best_accuracy['classifier__solver'],\n",
    "                                            max_iter = 5000,\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION MODEL\n",
    "    solution_log['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_precision:\n",
    "        precision_model = LogisticRegression(penalty = best_precision['classifier__penalty'],\n",
    "                                             C = best_precision['classifier__C'],\n",
    "                                             solver = best_precision['classifier__solver'],\n",
    "                                             max_iter = 5000,\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    else:\n",
    "        precision_model = LogisticRegression(penalty = best_precision['classifier__penalty'],\n",
    "                                             solver = best_precision['classifier__solver'],\n",
    "                                             max_iter = 5000,\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC MODEL\n",
    "    solution_log['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_roc_auc:\n",
    "        roc_model = LogisticRegression(penalty = best_roc_auc['classifier__penalty'],\n",
    "                                       C = best_roc_auc['classifier__C'],\n",
    "                                       solver = best_roc_auc['classifier__solver'],\n",
    "                                       max_iter = 5000,\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    else:\n",
    "        roc_model = LogisticRegression(penalty = best_roc_auc['classifier__penalty'],\n",
    "                                       solver = best_roc_auc['classifier__solver'],\n",
    "                                       max_iter = 5000,\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1 MODEL\n",
    "    solution_log['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    \n",
    "    \n",
    "    # creating new model with optimal hyperparameters\n",
    "    if 'classifier__C' in best_f1:\n",
    "        f1_model = LogisticRegression(penalty = best_f1['classifier__penalty'],\n",
    "                                      C = best_f1['classifier__C'],\n",
    "                                      solver = best_f1['classifier__solver'],\n",
    "                                      max_iter = 5000,\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    else:\n",
    "        f1_model = LogisticRegression(penalty = best_f1['classifier__penalty'],\n",
    "                                      solver = best_f1['classifier__solver'],\n",
    "                                      max_iter = 5000,\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    \n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "    \n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_log = train_metrics_log.append({'LG: Accuracy': acc_train_score, 'LG: Precision': prec_train_score, \n",
    "                                          'LG: AUC': roc_train_score, 'LG: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_log = test_metrics_log.append({'LG: Accuracy': acc_test_score, 'LG: Precision': prec_test_score, \n",
    "                                          'LG: AUC': roc_test_score, 'LG: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_log, test_metrics_log, solution_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def randomForest(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_rf = pd.DataFrame(columns=['RF: Accuracy','RF: Precision','RF: AUC','RF: F1'])\n",
    "    test_metrics_rf = pd.DataFrame(columns=['RF: Accuracy','RF: Precision','RF: AUC','RF: F1'])\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "\n",
    "    # Setting parameters according to CNM06\n",
    "    param_grid = {\n",
    "        'n_estimators': [1024],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features': [1,2,4,6,8,12,16],\n",
    "        'n_jobs': [-1],\n",
    "        'class_weight': ['balanced']}\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(estimator=randomForest, param_grid=param_grid, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "\n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_rf = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY MODEL\n",
    "    solution_rf['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    accuracy_model = RandomForestClassifier(n_estimators = best_accuracy['n_estimators'],\n",
    "                                            criterion = best_accuracy['criterion'],\n",
    "                                            max_features = best_accuracy['max_features'],\n",
    "                                            n_jobs = -1,\n",
    "                                            class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION MODEL\n",
    "    solution_rf['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    precision_model = RandomForestClassifier(n_estimators = best_precision['n_estimators'],\n",
    "                                             criterion = best_precision['criterion'],\n",
    "                                             max_features = best_precision['max_features'],\n",
    "                                             n_jobs = -1,\n",
    "                                             class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC MODEL\n",
    "    solution_rf['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    roc_model = RandomForestClassifier(n_estimators = best_roc_auc['n_estimators'],\n",
    "                                       criterion = best_roc_auc['criterion'],\n",
    "                                       max_features = best_roc_auc['max_features'],\n",
    "                                       n_jobs = -1,\n",
    "                                       class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1 MODEL\n",
    "    solution_rf['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    f1_model = RandomForestClassifier(n_estimators = best_f1['n_estimators'],\n",
    "                                      criterion = best_f1['criterion'],\n",
    "                                      max_features = best_f1['max_features'],\n",
    "                                      n_jobs = -1,\n",
    "                                      class_weight='balanced')\n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_rf = train_metrics_rf.append({'RF: Accuracy': acc_train_score, 'RF: Precision': prec_train_score,\n",
    "                                                'RF: AUC': roc_train_score, 'RF: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_rf = test_metrics_rf.append({'RF: Accuracy': acc_test_score, 'RF: Precision': prec_test_score,\n",
    "                                              'RF: AUC': roc_test_score, 'RF: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_rf, test_metrics_rf, solution_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTrees(X_train, X_test, y_train, y_test):\n",
    "    train_metrics_dt = pd.DataFrame(columns=['DT: Accuracy','DT: Precision','DT: AUC','DT: F1'])\n",
    "    test_metrics_dt = pd.DataFrame(columns=['DT: Accuracy','DT: Precision','DT: AUC','DT: F1'])\n",
    "\n",
    "    pipe = Pipeline(steps=[('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "    # Setting parameters according to CNM06 + passing a list of min_samples_leaf\n",
    "    parameters = [{'classifier': [DecisionTreeClassifier(class_weight='balanced')],\n",
    "                   'classifier__criterion': ['gini', 'entropy'],\n",
    "                   'classifier__splitter': ['best'],\n",
    "                   'classifier__min_samples_leaf': [1,2,4,6,8,10,12,14,16,18]}]\n",
    "\n",
    "    # Perform 5-fold cross-validation using grid search\n",
    "    clf = GridSearchCV(estimator=pipe, param_grid=parameters, cv=StratifiedKFold(n_splits=5), \n",
    "                       scoring=['accuracy', 'precision', 'roc_auc', 'f1'], refit=False, verbose=1)\n",
    "    \n",
    "    # Fitting training set on the cross validation\n",
    "    hyperparams = clf.fit(X_train, y_train)\n",
    "    # Storing best parameters for each metric model\n",
    "    results = hyperparams.cv_results_['params']\n",
    "    solution_dt = pd.DataFrame(results)\n",
    "\n",
    "    # ACCURACY\n",
    "    solution_dt['Accuracy'] = hyperparams.cv_results_['mean_test_accuracy']\n",
    "    best_accuracy = results[np.argmin(hyperparams.cv_results_['rank_test_accuracy'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    accuracy_model = DecisionTreeClassifier(criterion = best_accuracy['classifier__criterion'],\n",
    "                                            splitter = best_accuracy['classifier__splitter'],\n",
    "                                            min_samples_leaf = best_accuracy['classifier__min_samples_leaf'],\n",
    "                                            class_weight = 'balanced')\n",
    "\n",
    "    # Training on the new model\n",
    "    accuracy_model.fit(X_train, y_train)\n",
    "    y_acc_train = accuracy_model.predict(X_train)\n",
    "    acc_train_score = accuracy_score(y_train, y_acc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_acc_test = accuracy_model.predict(X_test)\n",
    "    acc_test_score = accuracy_score(y_test, y_acc_test)\n",
    "\n",
    "    # PRECISION\n",
    "    solution_dt['Precision'] = hyperparams.cv_results_['mean_test_precision']\n",
    "    best_precision = results[np.argmin(hyperparams.cv_results_['rank_test_precision'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    precision_model = DecisionTreeClassifier(criterion = best_precision['classifier__criterion'],\n",
    "                                             splitter = best_precision['classifier__splitter'],\n",
    "                                             min_samples_leaf = best_precision['classifier__min_samples_leaf'],\n",
    "                                             class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    precision_model.fit(X_train, y_train)\n",
    "    y_prec_train = precision_model.predict(X_train)\n",
    "    prec_train_score = precision_score(y_train, y_prec_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_prec_test = precision_model.predict(X_test)\n",
    "    prec_test_score = precision_score(y_test, y_prec_test)\n",
    "\n",
    "    # ROC AUC\n",
    "    solution_dt['ROC AUC'] = hyperparams.cv_results_['mean_test_roc_auc']\n",
    "    best_roc_auc = results[np.argmin(hyperparams.cv_results_['rank_test_roc_auc'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    roc_model = DecisionTreeClassifier(criterion = best_roc_auc['classifier__criterion'],\n",
    "                                       splitter = best_roc_auc['classifier__splitter'],\n",
    "                                       min_samples_leaf = best_roc_auc['classifier__min_samples_leaf'],\n",
    "                                       class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    roc_model.fit(X_train, y_train)\n",
    "    y_roc_train = roc_model.predict(X_train)\n",
    "    roc_train_score = roc_auc_score(y_train, y_roc_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_roc_test = roc_model.predict(X_test)\n",
    "    roc_test_score = roc_auc_score(y_test, y_roc_test)\n",
    "\n",
    "    # F1\n",
    "    solution_dt['F1'] = hyperparams.cv_results_['mean_test_f1']\n",
    "    best_f1 = results[np.argmin(hyperparams.cv_results_['rank_test_f1'])]\n",
    "    # creating new model with optimal hyperparameters\n",
    "    f1_model = DecisionTreeClassifier(criterion = best_f1['classifier__criterion'],\n",
    "                                      splitter = best_f1['classifier__splitter'],\n",
    "                                      min_samples_leaf = best_f1['classifier__min_samples_leaf'],\n",
    "                                      class_weight = 'balanced')\n",
    "    # Training on the new model\n",
    "    f1_model.fit(X_train, y_train)\n",
    "    y_f1_train = f1_model.predict(X_train)\n",
    "    f1_train_score = f1_score(y_train, y_f1_train)\n",
    "\n",
    "    # Testing and scoring the model\n",
    "    y_f1_test = f1_model.predict(X_test)\n",
    "    f1_test_score = f1_score(y_test, y_f1_test)\n",
    "\n",
    "    train_metrics_dt = train_metrics_dt.append({'DT: Accuracy': acc_train_score, 'DT: Precision': prec_train_score,\n",
    "                                                'DT: AUC': roc_train_score, 'DT: F1': f1_train_score}, ignore_index=True)\n",
    "\n",
    "    test_metrics_dt = test_metrics_dt.append({'DT: Accuracy': acc_test_score, 'DT: Precision': prec_test_score,\n",
    "                                              'DT: AUC': roc_test_score, 'DT: F1': f1_test_score}, ignore_index=True)\n",
    "    \n",
    "    return train_metrics_dt, test_metrics_dt, solution_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING DATASET ON ALL THREE ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 32.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed: 19.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:   17.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 45.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    9.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 205 out of 205 | elapsed: 10.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 110 out of 110 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "trials = 5\n",
    "train_metrics = pd.DataFrame()\n",
    "test_metrics = pd.DataFrame()\n",
    "solution_metrics = pd.DataFrame()\n",
    "\n",
    "# Running the trial five times\n",
    "for i in range(trials):\n",
    "    # Splitting data into train size = 5000\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, shuffle=True)\n",
    "    \n",
    "    train_log, test_log, solution_log = logisticRegression(X_train, X_test, y_train, y_test)\n",
    "    train_rf, test_rf, solution_rf = randomForest(X_train, X_test, y_train, y_test)\n",
    "    train_dt, test_dt, solution_dt = decisionTrees(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    train_metrics = train_metrics.append(pd.concat([train_log, train_rf, train_dt], axis=1))\n",
    "    test_metrics = test_metrics.append(pd.concat([test_log, test_rf, test_dt], axis=1))\n",
    "    solution_metrics = solution_metrics.append(pd.concat([solution_log, solution_rf, solution_dt], axis=1))\n",
    "\n",
    "# storing data into CSV file\n",
    "train_metrics.to_csv('adult_train.csv')\n",
    "test_metrics.to_csv('adult_test.csv')\n",
    "solution_metrics.to_csv('adult_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
